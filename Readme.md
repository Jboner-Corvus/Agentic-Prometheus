# üî® Agentic Forge

### Une Alternative a MANUS Priv√©e et Locale

![Agentic Forge Logo](https://img.shields.io/badge/üî®-Agentic_Forge-orange?style=for-the-badge)

**Fran√ßais** | [English](#english) | [‰∏≠Êñá](#‰∏≠Êñá) | [Espa√±ol](#espa√±ol)

Un agent IA autonome **100% local** qui forge ses propres outils, √©crit du code et ex√©cute des t√¢ches complexes tout en gardant toutes les donn√©es sur votre appareil. Bas√© sur le **protocole MCP (Model Context Protocol)** avec **FastMCP** comme fus√©e propulsive, il est con√ßu pour les mod√®les de raisonnement locaux et adaptable √† l'API de votre LLM favori, garantissant une confidentialit√© compl√®te et aucune d√©pendance cloud.

[![Licence](https://img.shields.io/badge/Licence-MIT-blue.svg)](LICENSE)
[![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white)](https://docker.com)
[![GitHub stars](https://img.shields.io/github/stars/votre-username/agentic-forge?style=social)](https://github.com/votre-username/agentic-forge)

---

## Pourquoi Agentic Forge ?

üîí **Enti√®rement Local et Priv√©** - Tout fonctionne sur votre machine ‚Äî pas de cloud, pas de partage de donn√©es. Vos fichiers, conversations et outils restent priv√©s.

üõ†Ô∏è **Auto-Forge d'Outils** - Agentic Forge peut cr√©er ses propres outils ‚Äî quand une capacit√© lui manque, il √©crit le code pour la construire.

üíª **Assistant de Codage Autonome** - Besoin de code ? Il peut √©crire, d√©boguer et ex√©cuter des programmes en Python, TypeScript, Bash et plus ‚Äî sans supervision.

üß† **S√©lection Intelligente d'Outils** - Vous demandez, il trouve automatiquement le meilleur outil pour le travail. Comme avoir une forge d'experts pr√™ts √† aider.

üìã **Planifie et Ex√©cute des T√¢ches Complexes** - De la gestion de fichiers au scraping web ‚Äî il peut diviser les grandes t√¢ches en √©tapes et forger les outils pour accomplir le travail.

üåê **Navigation Web Intelligente** - Agentic Forge peut naviguer sur internet de mani√®re autonome ‚Äî rechercher, lire, extraire des infos, automatiser des t√¢ches ‚Äî le tout sans intervention.

üöÄ **Propuls√© par FastMCP** - Utilise le protocole MCP (Model Context Protocol) avec FastMCP comme framework ultra-performant ‚Äî une v√©ritable fus√©e pour les interactions LLM.

---

## D√©mo

> **"Peux-tu cr√©er un outil pour analyser mes fichiers CSV, puis l'utiliser pour g√©n√©rer un rapport √† partir de donnees_ventes.csv ?"**

---

## üõ†Ô∏è ‚ö†Ô∏è Travail Actif en Cours

üôè Ce projet a commenc√© comme une exploration des agents IA auto-am√©liorants et a grandi au-del√† des attentes. Les contributions, commentaires et patience sont profond√©ment appr√©ci√©s alors que nous forgeons de l'avant.

---

## Pr√©requis

Avant de commencer, assurez-vous d'avoir les logiciels suivants install√©s :

-   **Git** : Pour cloner le d√©p√¥t. [T√©l√©charger Git](https://git-scm.com/)
-   **Docker Engine & Docker Compose** : Pour ex√©cuter les services group√©s.
    -   [Installer Docker Desktop](https://www.docker.com/products/docker-desktop/) (inclut Docker Compose V2) : Windows | Mac | Linux
    -   Ou installer s√©par√©ment : [Docker Engine](https://docs.docker.com/engine/install/) | [Docker Compose](https://docs.docker.com/compose/install/)
-   **Node.js 20+** : Pour l'interface web. [T√©l√©charger Node.js](https://nodejs.org/)
-   **pnpm** : Gestionnaire de paquets. Installer avec `npm install -g pnpm`

---

## 1. Cloner le d√©p√¥t

```bash
git clone [https://github.com/votre-username/agentic-forge.git](https://github.com/votre-username/agentic-forge.git)
cd agentic-forge
```

## 2. Lancer le script d'installation

Rendez le script de gestion ex√©cutable et lancez-le.

```bash
chmod +x run.sh
./run.sh
```

√Ä la premi√®re ex√©cution, le script v√©rifiera si un fichier `.env` existe. S'il n'existe pas, il le cr√©era automatiquement pour vous.

## 3. Configurer votre environnement

Une fois le fichier `.env` cr√©√©, ouvrez-le et remplissez les valeurs avec vos propres informations d'identification.

```env
# Copiez ce fichier en .env et remplissez les valeurs.
HOST_PORT=8080
PORT=8080
NODE_ENV=development
LOG_LEVEL=info
AUTH_TOKEN=""
REDIS_HOST=redis
REDIS_PORT=6378
REDIS_HOST_PORT=6378
REDIS_PASSWORD=""
# L'URL de base n'est plus n√©cessaire pour l'API Google, commentez-la ou supprimez-la.
# LLM_API_BASE_URL=
WEB_PORT=3000
# Utilisez votre cl√© d'API Google Gemini
LLM_API_KEY=""

# Sp√©cifiez un mod√®le Gemini, par exemple "gemini-1.5-pro-latest"
LLM_MODEL_NAME=gemini-2.5-flash
PYTHON_SANDBOX_IMAGE="python:3.11-slim"
BASH_SANDBOX_IMAGE="alpine:latest"
CODE_EXECUTION_TIMEOUT_MS=60000
```

**Important** :
-   D√©finissez un `AUTH_TOKEN` fort (32+ caract√®res recommand√©s)
-   Les cl√©s API sont optionnelles si vous utilisez des mod√®les locaux

---

## 4. D√©marrer Docker

Assurez-vous que Docker est en cours d'ex√©cution avant de continuer.

---

## Configuration pour LLM Local (Recommand√©)

### Exigences Mat√©rielles

| Taille Mod√®le | M√©moire GPU | Performance |
| --- | --- | --- |
| 7B | 8GB VRAM | ‚ö†Ô∏è T√¢ches basiques seulement |
| 14B | 12GB VRAM | ‚úÖ La plupart des t√¢ches fonctionnent bien |
| 32B | 24GB VRAM | üöÄ Excellentes performances |
| 70B+ | 48GB+ VRAM | üí™ Qualit√© professionnelle |

### Configuration avec Ollama (Recommand√©)

1.  **Installer Ollama** : [T√©l√©charger Ollama](https://ollama.ai/)
2.  **D√©marrer Ollama** :
    ```bash
    ollama serve
    ```
3.  **T√©l√©charger un mod√®le de raisonnement** :
    ```bash
    ollama pull deepseek-r1:14b
    # ou pour plus de puissance : ollama pull deepseek-r1:32b
    ```
4.  **Mettre √† jour la configuration** dans `.env` :
    ```env
    LLM_MODEL_NAME="deepseek-r1:14b"
    LLM_API_BASE_URL="http://localhost:11434"
    ```

---

## D√©marrer les Services et Ex√©cuter

### Utiliser la Console de Gestion (`run.sh`)

Apr√®s avoir configur√© votre fichier `.env`, utilisez la console de gestion pour d√©marrer l'application.

Lancez la console interactive :
```bash
./run.sh
```

Depuis le menu de la console :
1.  **D√©marrer** - Lancer tous les services
2.  **Statut** - V√©rifier la sant√© des services
3.  **Logs** - Surveiller les logs en temps r√©el

---

## Points d'Acc√®s

Une fois les services en marche :

| Service | URL | Description |
| --- | --- | --- |
| **Interface Web** | http://localhost:3000 | Interface utilisateur principale |
| **Point d'API** | http://localhost:8080/api/v1/agent/stream | Acc√®s API direct |
| **V√©rification Sant√©** | http://localhost:8080/health | Statut de sant√© des services |

---

*Le reste du fichier README.md peut rester tel quel car il d√©crit les fonctionnalit√©s, l'architecture et le d√©pannage qui ne sont pas affect√©s par ce changement.*
